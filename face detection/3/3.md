# Readme.md


# Introduction
MindSpore is a new generation of full-scenario AI computing framework launched by Huawei in August 2019 and released On March 28, 2020.

Facial Expression Recognition (FER) is an important task in computer vision and has wide applications in many fields.

This repository is about CIMC's approach to the fifth Affective Behavior Analysis in-the-wild (ABAW) Competition which will be held in CVPR2023. In the 5th ABAW competition, this approach achieves great performance on official validation and test sets, which proves the effectiveness of the approach.We implemented one version by mindspore.

This approach proposes a semi-supervised learning framework for the task of facial expression recognition. It can apply the unlabeled faces data to the task of facial expression recognition through the use of pseudo labels, which greatly alleviates the problem of small-scale facial expression datasets. This approach  designs a dynamic threshold module (DTM) for the Semi-Supervised Learning method. It can dynamically adjust the confidence threshold for different stages of training and different expression categories, to fully utilize the unlabeled faces to generate pseudo labels.

# Updates
Comming soon!


# Affwild2 Performance

The 5th Workshop and Competition on Affective Behavior Analysis in-the-wild provides the Affwild2 database as the official datasets. For EXPR Classification Challenge, This database is audiovisual (A/V) and in total consists of 548 videos of around 2.7M frames that are annotated in terms of the 6 basic expressions (i.e., anger, disgust, fear, happiness, sadness, surprise), plus the neutral state, plus a category ’other’ that denotes expressions/affective states other than the 6 basic ones.


| Teams | F1 on Validation Set | F1 on Test Set | 
| :-- | :-: | :-: |
| [baseline](https://arxiv.org/abs/2202.10659) | 23 | 20.50 |
| [DGU-IPL](https://arxiv.org/abs/2303.08419) | 27.77 | 22.78 |
| [CtyunAI](https://arxiv.org/abs/2303.08356) | 37.67 | 35.32 |
| [HFUT-MAC](https://arxiv.org/abs/2303.09158) | 40.55 | 33.37 |
| [HSE-NN-SberAI](https://arxiv.org/abs/2303.09162) | 43.3 | 32.92 |
| [AlphaAff](https://arxiv.org/abs/2303.10511) | 37.57 | 32.18 |
| ours| 43.36 | 35.34 |


# Quick Start
1. Installation

    1.1 Git clone this repo

    ```
    git clone https://github.com/harryjun-ustc/MindFace.git
    ```

    1.2 Install dependencies

    ```
    pip install -r requirements.txt
    ```

2. Prepare Data

    2.1.
   
   Affwild2 Data:
   
    The videos can be found [here](https://drive.google.com/file/d/1o-ZIvjmpq34zaRb6empLV3W7LFx_8Rvb/view), [here](https://drive.google.com/file/d/1LTzpMJilzrl7HvpintPo2JXLYswONl7y/view) and [here](https://drive.google.com/file/d/1mLb75Lt2nhNk5PHf48AOgCThCBvDPBW_/view).
   
    These links contain the training, validation and test videos for the 3 Challenges.
   
    The corresponding cropped images for the above videos can be found [here](https://drive.google.com/file/d/1eLjxfV4VSntpVmIZb7i2xcgyLqRDF0T0/view), [here](https://drive.google.com/file/d/1hKZc7Pzq-fM91osFgFf0l0JN0SXp0GXw/view) and [here](https://drive.google.com/file/d/1gsvGZXVSMRExrC_JXFyHEku96nAPROk3/view). 
    The corresponding cropped and aligned images for the above videos can be found [here](https://drive.google.com/open?id=1mJdgQviC5i2IFlmMKFkZwG8_RwHFSRrX) and 
    [here](https://drive.google.com/file/d/1iz73GCNlUEqKTOVSH_7OKmGk0L-Oj4bE/view).
   
    All cropped-aligned images have the same dimensions: 112 x 112 x 3.
   
   Affwild2 Anotations:
   
    The annotation files for the training and validation videos for all Challenges can be found [here](https://drive.google.com/file/d/1js-aOtUZcAaBvvvRsfnrRsYW5Dbb87b2/view).
   
    In this link you will find three folders named: VA_Estimation_Challenge, EXPR_Classification_Challenge and AU_Detection_Challenge. 

    [AffectNet](http://mohammadmahoor.com/affectnet/)and [ExpW](https://mmlab.ie.cuhk.edu.hk/projects/socialrelation/index.html)
    
    2.2. Organise the dataset directory under /data as follows:
    ```
    data/
        label_train_img/
        label_train.csv
        unlabel_train_img/
        val_img/
        val.csv
        test_img/
        test.csv
    ```
4. Set Config File

    You can Modify the parameters of the config file in ```model/config```.

5. Train


```
    python train.py
```

5. Predict
```
    python test.py 
```

## References
- [Exploring Large-scale Unlabeled Faces to Enhance Facial Expression Recognition](https://openaccess.thecvf.com/content/CVPR2023W/ABAW/html/Yu_Exploring_Large-Scale_Unlabeled_Faces_To_Enhance_Facial_Expression_Recognition_CVPRW_2023_paper.html)
```
@inproceedings{yu2023dual,
title={Exploring Large-scale Unlabeled Faces to Enhance Facial Expression Recognition},
author={Jun Yu, Zhongpeng Cai, Renda Li, Gongpeng Zhao, Guochen Xie, Jichao Zhu, Wangyuan Zhu, Qiang Ling, Lei Wang, Cong Wang, Luyu Qiu, Wei Zheng},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
pages={5803-5810},
year={2023}
}
```

- [ABAW 5th Challenges](https://arxiv.org/abs/2303.01498)
```
@inproceedings{kollias2023abaw2,
title={Abaw: Valence-arousal estimation, expression recognition, action unit detection \& emotional reaction intensity estimation challenges},
author={Kollias, Dimitrios and Tzirakis, Panagiotis and Baird, Alice and Cowen, Alan and Zafeiriou, Stefanos},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
pages={5888--5897},
year={2023}}
```
